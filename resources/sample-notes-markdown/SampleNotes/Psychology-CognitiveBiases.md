Cognitive biases in humans refer to systematic patterns of deviation from norm or rationality in judgment, which often affect decision-making and problem-solving. Common cognitive biases include confirmation bias (favoring information that confirms pre-existing beliefs), anchoring bias (relying too heavily on the first piece of information encountered), and availability heuristic (basing decisions on immediate examples that come to mind). These biases can lead to errors in judgment, irrational decisions, and difficulties in critical thinking, especially in complex or ambiguous situations. On the other hand, biases in AI decision-making systems arise from the data the algorithms are trained on and the design choices made during model development. AI systems can inherit biases from the data they process, leading to discriminatory outcomes, such as racial or gender biases in hiring algorithms or facial recognition technology. Additionally, AI systems can be influenced by algorithmic biases, which emerge when the design or training of the model inadvertently favors certain outcomes over others. While human biases are often the result of cognitive limitations and social influences, AI biases are typically due to incomplete, unrepresentative, or biased datasets, or improper model tuning. Both human and AI biases can result in unfair or flawed decisions, making it critical to develop strategies for mitigating these biases through techniques like data diversity, model transparency, and continuous monitoring.